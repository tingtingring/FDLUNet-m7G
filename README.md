FTNet: Frequency-aware Transformer U-Net for RNA Modification Site Prediction

This repository provides the implementation of FTNet, a deep learning framework for RNA modification site prediction.
FTNet integrates frequency-domain decomposition, 1D U-Net, and Transformer-based contextual modeling to capture both local and global sequence patterns.

ğŸ”¬ Model Overview

FTNet is designed for binary classification of RNA modification sites (e.g. m7G, m1A, m5C, A-to-I).

Key components:

One-hot encoding (1-mer) of RNA/DNA sequences

Initial CNN encoder for low-level feature extraction

Frequency-domain decomposition (FFT):

Low-frequency branch

High-frequency branch

Raw (time-domain) branch

Three parallel U-Net + Transformer branches

Feature fusion with channel-wise attention

Center-position classification head

ğŸ§  Architecture
Input Sequence
     â”‚
1-mer Encoding + One-hot
     â”‚
Initial CNN
     â”‚
FFT Decomposition
 â”Œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¬â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¬â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”
 â”‚ Low-freq  â”‚ High-freq â”‚ Raw        â”‚
 â”‚  U-Net +  â”‚ U-Net +   â”‚ U-Net +    â”‚
 â”‚ Transformerâ”‚Transformerâ”‚Transformerâ”‚
 â””â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”´â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”´â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”˜
     â”‚
Feature Fusion (FC-based attention)
     â”‚
Center Position Feature
     â”‚
Binary Classification

ğŸ“ Project Structure
.
â”œâ”€â”€ unet_cnn_ft.py        # FTNet model definition
â”œâ”€â”€ train.py              # Training and evaluation script
â”œâ”€â”€ data/                 # FASTA datasets
â”‚   â””â”€â”€ m7G/
â”‚       â”œâ”€â”€ train_ref.fasta
â”‚       â”œâ”€â”€ val_ref.fasta
â”‚       â””â”€â”€ test_ref.fasta
â”œâ”€â”€ save/                 # Saved model checkpoints
â”œâ”€â”€ results/              # Training logs
â””â”€â”€ README.md

ğŸ§¬ Input Data Format

FASTA format is required.

Example:
>chr19:34401574|1|train
ATGCTAGCTAGCTAGCTAG...
>chr19:34401575|0|train
CGATCGATCGATCGATCGA...


Label is parsed from FASTA header:

1 â†’ positive sample

0 â†’ negative sample

RNA bases (U) will be automatically converted to T

âš™ï¸ Environment Requirements

Python â‰¥ 3.8

PyTorch â‰¥ 1.10

CUDA-enabled GPU (recommended)

Required packages
pip install torch numpy pandas scikit-learn tqdm termcolor tensorboard

ğŸš€ Training
Step 1: Set GPU
export CUDA_VISIBLE_DEVICES=0


(or modify it directly in the code)

Step 2: Configure Hyperparameters

In train.py:

params = {
    'lr': 1e-4,
    'batch_size': 64,
    'epoch': 100,
    'seq_len': 201,
    'seed': 17,
    'patience': 10,
    'index': 10
}

Step 3: Run Training
python train.py

ğŸ“Š Evaluation Metrics

The following metrics are reported:

Accuracy (ACC)

Balanced Accuracy (BACC)

Sensitivity (SE)

Specificity (SP)

Matthews Correlation Coefficient (MCC)

Area Under ROC Curve (AUC)

Early stopping is applied based on validation accuracy.

ğŸ’¾ Model Checkpoints

Best models are saved automatically:

save/seq_len201/seed17_YYYYMMDD_HHMMSS_acc0.XXXX.pth


Each checkpoint includes:

Model weights

Best validation accuracy

Training epoch

Hyperparameters

ğŸ§ª Supported Tasks

The framework supports multiple RNA modification datasets by changing data loaders:

m7G

m1A

m5C

A-to-I

Custom FASTA datasets

You can switch datasets by modifying the read_fasta_* function calls in evaluation_method().

ğŸ“Œ Reproducibility

Fixed random seeds

Deterministic CUDA settings enabled

Same sequence centering and padding strategy across datasets

ğŸ“¬ Contact

If you have questions or want to collaborate, feel free to open an issue or contact the author.
